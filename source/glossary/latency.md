---
title: Latency
extends: _layouts.documentation
section: content
---

Latency is a term used to describe the amount of time it takes for data to travel between two points in a computer network. 

It is a measure of the delay that occurs when data is transmitted from one point to another, and is usually expressed in milliseconds (ms). Latency can be affected by various factors, including the distance between the two points, the speed of the network connection, the quality of the network infrastructure, and the processing time required by the devices involved. 

In general, lower latency is desirable, as it means that data can be transmitted more quickly and with less delay. However, achieving low latency can be challenging in complex networks or in situations where large amounts of data need to be transmitted over long distances. 

Latency is an important consideration in many areas of computing, including online gaming, video streaming, and real-time communication applications.